{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting up Prefect\n",
    "\n",
    "Prefect is an orchestration tool, this is a flow of everything that runs in a database load... The pulling of data, validating, loading, transforming, etc, etc. See it as an altenative to SSIS & SQL Agent Jobs, that looks and works a lot nicer!\n",
    "\n",
    "It also means that we don't have to be tied down to a single toolset to accoplish things, if something would be better done in python which then kicks off a bit of SQL, the orchestration sets that us for us.\n",
    "\n",
    "Prefect is a python module that uses _decorators_ to orchestrate the data flow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from prefect  import flow\n",
    "\n",
    "@flow\n",
    "def my_first_flow():\n",
    "    print(\"This function doesn't do too much\")\n",
    "    return 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We set up a basic function that is decorated with `@flow` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = my_first_flow()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(state)\n",
    "print(state.result())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## So what happened here?\n",
    "\n",
    "1. We created a basic function that prints something and returns something\n",
    "2. Decorated it with `@flow`\n",
    "3. Assigned the output of the function to variable `state` which we can then query. The output is a Prefect `State` object, to see what is returned we need to access it via `.result()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(state))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Flows and tasks\n",
    "\n",
    "Flows and tasks are the basic blocks of Prefect, they are containers for the workflow logic. Flows can run other flows or tasks; tasks are optional, but provide extra encapsulation in observable units that can be reused across flows and subflows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "from prefect import flow, task\n",
    "\n",
    "@task\n",
    "def call_api(url):\n",
    "    response = requests.get(url)\n",
    "    print(response.status_code)\n",
    "    return response.json()\n",
    "\n",
    "@task\n",
    "def parse_fact(response):\n",
    "    print(response[\"fact\"])\n",
    "    return\n",
    "\n",
    "@flow(name=\"Example API call flow\",\n",
    "     description=\"An example flow for this tutorial\",\n",
    "     version=os.getenv(\"GIT_COMMIT_SHA\"))\n",
    "def api_flow(url):\n",
    "    fact_json = call_api(url)\n",
    "    parse_fact(fact_json)\n",
    "    return\n",
    "\n",
    "state=api_flow(\"https://catfact.ninja/fact\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying this to NHS Numbers\n",
    "\n",
    "So now we have the basics, let's apply it to our OptOut csv.\n",
    "\n",
    "### The way we'll do it\n",
    "\n",
    "1. Simulate csv delivery - just copy a file from one area to the source folder\n",
    "2. Validate data with great expectations\n",
    "3. Run checksum against data\n",
    "4. Load csv to dataframe, save as a timestamped csv + load into a database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22:18:57.751 | INFO    | prefect.engine - Created flow run 'carmine-duck' for flow 'OptOuts Prefect Flow'\n",
      "22:18:57.755 | INFO    | Flow run 'carmine-duck' - Using task runner 'ConcurrentTaskRunner'\n",
      "22:18:57.795 | WARNING | Flow run 'carmine-duck' - No default storage is configured on the server. Results from this flow run will be stored in a temporary directory in its runtime environment.\n",
      "22:18:57.887 | INFO    | Flow run 'carmine-duck' - Created task run 'Copy file to dropzone-046d9bd5-0' for task 'Copy file to dropzone'\n",
      "22:18:57.965 | INFO    | Flow run 'carmine-duck' - Created task run 'Validate Data-d13a1dbb-0' for task 'Validate Data'\n",
      "22:18:57.998 | INFO    | Task run 'Copy file to dropzone-046d9bd5-0' - Finished in state Completed()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File copied\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22:19:01.558 | WARNING | py.warnings - D:\\git\\dePOC\\.env\\dePOC\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "\n",
      "D:\\git\\dePOC\\.env\\dePOC\\lib\\site-packages\\great_expectations\\datasource\\data_connector\\runtime_data_connector.py:133: DeprecationWarning: Specifying batch_identifiers as part of the RuntimeDataConnector config is deprecated as of v0.15.1 and will be removed by v0.18. Please configure batch_identifiers as part of Assets instead.\n",
      "  warnings.warn(\n",
      "Calculating Metrics: 100%|████████████████████████████████████████████████████████████████████████████████████| 18/18 [00:00<00:00, 216.87it/s]\n",
      "D:\\git\\dePOC\\.env\\dePOC\\lib\\site-packages\\jinja2\\environment.py:1088: DeprecationWarning: 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.\n",
      "  return concat(self.root_render_func(self.new_context(vars)))\n",
      "22:19:06.926 | INFO    | Task run 'Validate Data-d13a1dbb-0' - Crash detected! Execution was aborted by Python system exit call.\n",
      "22:19:06.962 | ERROR   | Flow run 'carmine-duck' - Crash detected! Execution was aborted by Python system exit call.\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "import pandas as pd\n",
    "from prefect import flow, task\n",
    "\n",
    "@task(name='Copy file to dropzone', description='A simulated drop of the OptOuts csv to the dropzone')\n",
    "def simulate_datadrop(sourcePath: str, destinationPath: str, file: str) -> None:\n",
    "    sourceFile = sourcePath + '\\\\' + file\n",
    "    destFile = destinationPath + '\\\\' + file\n",
    "    shutil.copyfile(sourceFile, destFile)\n",
    "    print(\"File copied\")\n",
    "    \n",
    "@task(name='Validate Data', description='Validate data against great expectations checkpoint')\n",
    "def validate_data(checkpointPath: str):\n",
    "    exec(open(checkpointPath).read())\n",
    "    \n",
    "    \n",
    "@flow(name='OptOuts Prefect Flow')\n",
    "def optout_flow():\n",
    "    simulate_datadrop('D:\\\\git\\\\dePOC\\\\data\\\\raw', 'D:\\\\git\\\\dePOC\\\\data\\\\src', 'OptOuts.csv')\n",
    "    validate_data('D:\\\\git\\\\dePOC\\\\expectations\\\\great_expectations\\\\uncommitted\\\\run_OptOuts_checkpoint.py')\n",
    "    return\n",
    "\n",
    "state = optout_flow()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "vscode": {
   "interpreter": {
    "hash": "d87b283dc860421bd1377802e21632de5fa8fbe197371923bf2364904eab60d4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
